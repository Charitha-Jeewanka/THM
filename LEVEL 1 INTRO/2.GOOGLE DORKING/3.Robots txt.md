# Robots.txt
- This file is the first thing indexed by "Crawlers" when visiting a website.
- This file must be served at the root directory - specified by the webserver itself.
- The text file defines the permissions the "Crawler" has to the website.
	- For example, what type of "Crawler" is allowed (I.e. You only want Google's "Crawler" to index your site and not MSN's).
	- Robots.txt can specify what files and directories that we do or don't want to be indexed by the "Crawler".
###### EXAMPLE
Basic Robots.txt file
![[THM/2.GOOGLE DORKING/IMG/I6.PNG]]

### Keywords
1. User-agent
	 - Specify the type of "Crawler" that can index your site (the asterisk being a wildcard, allowing **all "User-agents"**
2. Allow
	- Specify the directories or file(s) that the "Crawler" **can** index
3. Disallow
	- Specify the directories or file(s) that the "Crawler" **cannot** index
4. Sitemap
	- Provide a reference to where the sitemap is located

```
In this case:

1. Any "Crawler" can index the site

2. The "Crawler" is allowed to index the entire contents of the site

3. The "Sitemap" is located at [http://mywebsite.com/sitemap.xml](http://mywebsite.com/sitemap.xml)
```

Say we wanted to hide directories or files from a "Crawler"? Robots.txt works on a "blacklisting" basis. Essentially, **unless told otherwise**, the Crawler will index whatever it can find
![[THM/2.GOOGLE DORKING/IMG/I7.PNG]]

```
In this case:

1. Any "Crawler" can index the site  

2. The "Crawler" can index every other content that isn't contained within "/super-secret-directory/".

Crawlers also know the differences between sub-directories, directories and files. Such as in the case of the second "Disallow:" ("/not-a-secret/but-this-is/")

The "Crawler" will index all the contents within "**/not-a-secret/**", but will not index anything contained within the sub-directory **"/but-this-is/"**.

3. The "Sitemap" is located at [http://mywebsite.com/sitemap.xml](http://mywebsite.com/sitemap.xml)
```

### Aloowing certain Crawlers only
![[THM/2.GOOGLE DORKING/IMG/I8.PNG]]

### Preventing Files From Being Indexed
Whilst you can make manual entries for every file extension that you don't want to be indexed, you will have to provide the directory it is within, as well as the full filename. Imagine if you had a huge site! What a pain...Here's where we can use a bit of [regexing](https://www.rexegg.com/regex-quickstart.html).

![[THM/2.GOOGLE DORKING/IMG/I9.PNG]]
```
In this case:

1. Any "Crawler" can index the site

2. However, the "Crawler" cannot index **any** file that has the extension of **.ini** within any directory/sub-directory using ("$") of the site.

3. The "Sitemap" is located at [http://mywebsite.com/sitemap.xml](http://mywebsite.com/sitemap.xml)
```

[[4.Sitemaps]]